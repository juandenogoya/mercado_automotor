# ğŸ¤– Fase 4: Modelos de Forecasting

Sistema completo de entrenamiento y comparaciÃ³n de modelos para forecasting de operaciones del mercado automotor.

---

## ğŸ¯ Objetivo

Entrenar y comparar 2 modelos complementarios:
1. **Prophet** - Series temporales con estacionalidad (Facebook)
2. **XGBoost** - Gradient Boosting con mÃºltiples features

**Target:** Predecir `total_operaciones` mensuales (inscripciones + transferencias + prendas)

---

## ğŸ“‹ Prerequisitos

### 1. Dataset Unificado

Debe existir: `data/processed/dataset_forecasting_completo.parquet`

Si no existe, ejecutar:
```powershell
python backend/data_processing/ejecutar_pipeline_completa.py
```

### 2. Dependencias Python

```powershell
# Instalar dependencias de modelos
pip install -r backend/models/requirements_models.txt
```

**LibrerÃ­as requeridas:**
- `prophet>=1.1.5`
- `xgboost>=2.0.0`
- `scikit-learn>=1.3.0`
- `pandas`, `numpy`, `pyarrow`

---

## ğŸš€ Uso RÃ¡pido

### OpciÃ³n A: Entrenar y Comparar Ambos Modelos (RECOMENDADO) âš¡

```powershell
# Desde: mercado_automotor/
python backend/models/comparar_modelos.py
```

Esto ejecuta:
1. âœ… Entrena Prophet (~30 seg)
2. âœ… Entrena XGBoost (~20 seg)
3. âœ… Compara mÃ©tricas
4. âœ… Genera reporte comparativo

**Tiempo total:** ~1 minuto

---

### OpciÃ³n B: Entrenar Modelos Individualmente

```powershell
# Solo Prophet
python backend/models/train_prophet.py

# Solo XGBoost
python backend/models/train_xgboost.py
```

---

## ğŸ“Š Modelos Implementados

### 1. Prophet ğŸ“ˆ

**DescripciÃ³n:**
Modelo de Facebook diseÃ±ado para series temporales de negocios con estacionalidad fuerte.

**CaracterÃ­sticas:**
- Maneja estacionalidad automÃ¡ticamente (mensual, anual)
- Robusto a valores faltantes y outliers
- Interpreta componentes: tendencia + estacionalidad
- Puede incluir regresores externos (variables BCRA/INDEC)

**ConfiguraciÃ³n:**
```python
{
  'seasonality_mode': 'multiplicative',
  'yearly_seasonality': True,
  'changepoint_prior_scale': 0.05,
  'regresores': ['IPC', 'EMAE', 'TC', ...]  # Top 8 variables
}
```

**Features utilizadas:**
- Target: `total_operaciones`
- Regresores: Top 5 BCRA + Top 3 INDEC

---

### 2. XGBoost ğŸš€

**DescripciÃ³n:**
Gradient Boosting avanzado que maneja mÃºltiples features y relaciones complejas.

**CaracterÃ­sticas:**
- Usa TODAS las ~100 features del dataset
- Captura relaciones no-lineales
- Feature importance para interpretabilidad
- Early stopping para evitar overfitting

**ConfiguraciÃ³n:**
```python
{
  'n_estimators': 1000,
  'max_depth': 6,
  'learning_rate': 0.05,
  'subsample': 0.8,
  'colsample_bytree': 0.8,
  'early_stopping_rounds': 50
}
```

**Features utilizadas:**
- ~100 features numÃ©ricas:
  - Operaciones (4)
  - Top provincias (5) y marcas (5)
  - Variables BCRA (11)
  - Variables INDEC (5)
  - Features temporales (7)
  - Lags: 1, 3, 6, 12 meses (12)
  - Rolling means: 3, 6, 12 meses (9)
  - Features avanzadas: ratios, tendencias (5+)

---

## ğŸ“Š Estrategia de EvaluaciÃ³n

### Split Temporal (NO aleatorio)

```
Total: 80 meses

Train:      60 meses (75%)   â†’ Entrenar modelos
Validation: 10 meses (12.5%) â†’ Tuning y early stopping
Test:       10 meses (12.5%) â†’ EvaluaciÃ³n final
```

**Importante:** Split cronolÃ³gico, NO aleatorio.

### MÃ©tricas de EvaluaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trica â”‚ DescripciÃ³n                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RMSE    â”‚ Root Mean Squared Error (penaliza grandes errores) â”‚
â”‚ MAE     â”‚ Mean Absolute Error (error promedio)     â”‚
â”‚ MAPE    â”‚ Mean Absolute Percentage Error (% error) â”‚
â”‚ RÂ²      â”‚ Coeficiente de determinaciÃ³n (ajuste)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Todas se calculan en:** Train, Validation y Test

---

## ğŸ“ Archivos Generados

### Estructura de Output

```
mercado_automotor/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ prophet_model.pkl          # Modelo Prophet entrenado
â”‚   â””â”€â”€ xgboost_model.pkl          # Modelo XGBoost entrenado
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ prophet/
    â”‚   â”œâ”€â”€ predictions.parquet    # Predicciones (fecha, real, pred, bounds)
    â”‚   â”œâ”€â”€ metrics.json           # MÃ©tricas (train/val/test)
    â”‚   â””â”€â”€ components.parquet     # Componentes Prophet (tendencia, estacionalidad)
    â”‚
    â”œâ”€â”€ xgboost/
    â”‚   â”œâ”€â”€ predictions.parquet    # Predicciones (fecha, real, pred)
    â”‚   â”œâ”€â”€ metrics.json           # MÃ©tricas (train/val/test)
    â”‚   â””â”€â”€ feature_importance.parquet  # Importancia de features
    â”‚
    â””â”€â”€ comparison/
        â”œâ”€â”€ comparison_metrics.json     # ComparaciÃ³n completa
        â””â”€â”€ comparison_report.txt       # Reporte textual
```

---

## ğŸ“Š Ejemplo de Reporte de ComparaciÃ³n

```
================================================================================
REPORTE COMPARATIVO: PROPHET VS XGBOOST
================================================================================

ğŸ“Š MÃ‰TRICAS EN TEST:
--------------------------------------------------------------------------------
MÃ©trica         |         Prophet |         XGBoost |        Mejor |    Dif %
--------------------------------------------------------------------------------
RMSE            |        1,250.00 |        1,100.00 |      XGBoost |     12.0%
MAE             |          950.00 |          850.00 |      XGBoost |     10.5%
MAPE            |           8.50% |           7.20% |      XGBoost |     15.3%
R2              |          0.8200 |          0.8700 |      XGBoost |      6.1%
--------------------------------------------------------------------------------

ğŸ¯ RECOMENDACIÃ“N

âœ… XGBOOST es el modelo recomendado (4/4 mÃ©tricas)

Motivos:
  - Mejor performance en todas las mÃ©tricas
  - Captura relaciones complejas entre features
  - Feature importance para interpretabilidad
```

---

## ğŸ” AnÃ¡lisis Post-Entrenamiento

### 1. Ver MÃ©tricas

```python
import json

# Prophet
with open('results/prophet/metrics.json') as f:
    prophet_metrics = json.load(f)
    print(prophet_metrics['Test'])

# XGBoost
with open('results/xgboost/metrics.json') as f:
    xgboost_metrics = json.load(f)
    print(xgboost_metrics['Test'])
```

### 2. Ver Predicciones

```python
import pandas as pd

# Prophet
df_prophet = pd.read_parquet('results/prophet/predictions.parquet')
print(df_prophet.head())

# XGBoost
df_xgboost = pd.read_parquet('results/xgboost/predictions.parquet')
print(df_xgboost.head())
```

### 3. Feature Importance (XGBoost)

```python
df_importance = pd.read_parquet('results/xgboost/feature_importance.parquet')
print(df_importance.head(20))  # Top 20 features
```

### 4. Componentes (Prophet)

```python
df_components = pd.read_parquet('results/prophet/components.parquet')
# Columnas: ds, trend, yearly, yhat, yhat_lower, yhat_upper
print(df_components[['ds', 'trend', 'yearly', 'yhat']].head())
```

---

## ğŸ¨ PrÃ³ximas Mejoras (Opcional)

### 1. Visualizaciones

Crear grÃ¡ficos de:
- Predicciones vs Real (lÃ­nea temporal)
- Error por mes (barras)
- Componentes Prophet
- Feature importance XGBoost
- DistribuciÃ³n de errores

### 2. Ensemble

Combinar ambos modelos:
```python
pred_ensemble = 0.6 * pred_xgboost + 0.4 * pred_prophet
```

### 3. HiperparÃ¡metro Tuning

Usar GridSearch o Optuna para optimizar:
- Prophet: `changepoint_prior_scale`, `seasonality_prior_scale`
- XGBoost: `max_depth`, `learning_rate`, `n_estimators`

### 4. Modelos Adicionales

- LightGBM (mÃ¡s rÃ¡pido que XGBoost)
- CatBoost (maneja categÃ³ricas mejor)
- LSTM (deep learning para series temporales)

---

## ğŸ› Troubleshooting

### Error: "Prophet no estÃ¡ instalado"
```powershell
pip install prophet
```

**Nota Windows:** Prophet requiere compilador C++. Si falla:
```powershell
conda install -c conda-forge prophet
```

### Error: "XGBoost no estÃ¡ instalado"
```powershell
pip install xgboost
```

### Error: "Dataset no encontrado"
Ejecutar pipeline completa primero:
```powershell
python backend/data_processing/ejecutar_pipeline_completa.py
```

### Advertencia: "Convergence warnings" (Prophet)
Normal, no afecta performance. Prophet ajusta automÃ¡ticamente.

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Â¿QuÃ© mÃ©tricas importan mÃ¡s?

1. **MAPE** - Error porcentual, fÃ¡cil de interpretar
   - < 10%: Excelente
   - 10-20%: Bueno
   - > 20%: Necesita mejora

2. **RÂ²** - QuÃ© % de varianza explica el modelo
   - > 0.8: Muy bueno
   - 0.6-0.8: Bueno
   - < 0.6: Necesita mejora

3. **RMSE/MAE** - En escala del target
   - Comparar con media/std del target

### Â¿CuÃ¡ndo usar cada modelo?

**Usar Prophet si:**
- Necesitas interpretabilidad (tendencia + estacionalidad)
- Hay cambios de rÃ©gimen (eventos especiales)
- Datos con valores faltantes
- Forecasting a largo plazo

**Usar XGBoost si:**
- Tienes muchas features predictoras
- Relaciones complejas entre variables
- Necesitas mÃ¡xima precisiÃ³n
- Forecasting a corto/mediano plazo

**Usar Ensemble:**
- Cuando ambos tienen performance similar
- Para reducir riesgo y varianza

---

## ğŸ“ Soporte

Si encuentras problemas:
1. Verifica que el dataset existe
2. Verifica dependencias instaladas
3. Revisa logs de entrenamiento
4. Chequea mÃ©tricas en validation (puede haber overfitting)

---

**Ãšltima actualizaciÃ³n:** 2025-11-12
**VersiÃ³n:** 1.0
