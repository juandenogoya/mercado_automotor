# Mejoras Implementadas - Pipeline ML de Propensi√≥n de Compra

## üìÖ Fecha: 17 de Noviembre, 2025

## üéØ Objetivo
Implementar una metodolog√≠a robusta de validaci√≥n cruzada para el modelo de predicci√≥n de propensi√≥n de compra de marcas automotrices.

---

## ‚úÖ Cambios Implementados

### 1. **Versi√≥n LITE de Preparaci√≥n de Datos** ‚ö°
**Archivo:** `backend/ml/preparar_datos_propension_lite.py`

**Problema Resuelto:**
- La creaci√≥n de la tabla `ml_features_propension_compra` con todas las dimensiones tomaba 2-3 horas
- Bloqueaba el desarrollo iterativo del modelo

**Soluci√≥n:**
- Versi√≥n LITE que extrae features directamente desde las vistas KPI LITE existentes
- Usa JOINs para combinar: segmentaci√≥n demogr√°fica, financiamiento, antig√ºedad de veh√≠culos, demanda activa
- **Tiempo de ejecuci√≥n: ~10 segundos** (200x m√°s r√°pido)
- Genera 23,468 registros con 23 features

**Features Generadas:**
- Demogr√°ficas: provincia, marca, a√±o, mes
- Volumen: total_inscripciones, modelos_distintos
- Financiamiento: total_prendas, indice_financiamiento
- Antig√ºedad: evt_promedio (edad veh√≠culos transferencia), iam_promedio (edad inscripciones)
- Demanda: total_transferencias, indice_demanda_activa
- Tendencias: inscripciones_3m, inscripciones_6m, tendencia_3m, tendencia_6m
- Ratios: ratio_transferencias, ratio_prendas
- Segmentaci√≥n: edad_promedio, segmento_mercado
- Estacionalidad: mes_sin, mes_cos

**Mejoras T√©cnicas:**
- ‚úÖ Manejo correcto de tipo_transaccion en kpi_antiguedad_vehiculos_lite (2 JOINs separados)
- ‚úÖ Conversi√≥n de columnas categ√≥ricas a string antes de fillna('UNKNOWN')
- ‚úÖ Estratificaci√≥n con fallback para clases raras (< 2 ejemplos)
- ‚úÖ Recomendaci√≥n de usar TODOS los a√±os disponibles (no solo 2023-2024)

---

### 2. **Script de Entrenamiento con Cross-Validation** üî¨
**Archivo:** `backend/ml/entrenar_modelo_propension_cv.py`

**Motivaci√≥n del Usuario:**
> "no deberiamos entrenar al menos 3 modelos, para luego hacer un cross valitation?? o metodologias diferentes, para comparar resultados?"

**Implementaci√≥n:**
- **Stratified K-Fold Cross-Validation** con 5 folds
- Comparaci√≥n de m√∫ltiples modelos: Random Forest vs XGBoost (con opci√≥n para LightGBM)
- M√©tricas estad√≠sticas: Media ¬± Desviaci√≥n Est√°ndar en cada m√©trica
- Grid Search opcional para optimizaci√≥n de hiperpar√°metros

**M√©tricas Evaluadas:**
- Accuracy
- Precision (weighted)
- Recall (weighted)
- F1 Score (weighted)
- Top-3 Accuracy (predicci√≥n correcta en top 3)
- Top-5 Accuracy (predicci√≥n correcta en top 5)

**Arquitectura del Script:**
```
1. Cargar datasets (train/test)
2. Configurar Stratified K-Fold (5 folds)
3. Para cada modelo:
   a. Cross-validation en train set
      - Entrenar en 4 folds
      - Validar en 1 fold
      - Repetir 5 veces
   b. Calcular mean ¬± std de todas las m√©tricas
   c. Entrenar modelo final en todo el train set
   d. Evaluar en test set (holdout)
4. Comparar modelos
5. Guardar mejor modelo con metadata
```

**Hiperpar√°metros por Defecto:**
- **Random Forest:**
  - n_estimators: 200
  - max_depth: 20
  - min_samples_split: 5
  - min_samples_leaf: 2
  - class_weight: 'balanced'

- **XGBoost:**
  - n_estimators: 200
  - max_depth: 10
  - learning_rate: 0.1
  - subsample: 0.8
  - colsample_bytree: 0.8

---

### 3. **Correcciones T√©cnicas Cr√≠ticas** üîß

#### 3.1. Labels en top_k_accuracy_score - Cross-Validation
**Problema:**
```
ValueError: Number of given labels (100) not equal to the number of classes in 'y_score' (91)
```

**Causa:**
Cada fold de CV puede tener diferente n√∫mero de clases presentes. Pasar `labels` fijo causaba error.

**Soluci√≥n:**
```python
# ‚ùå INCORRECTO
'top3_accuracy': make_scorer(top_k_accuracy_score, k=3, labels=all_labels)

# ‚úÖ CORRECTO
'top3_accuracy': make_scorer(top_k_accuracy_score, k=3)  # sklearn maneja autom√°ticamente
```

#### 3.2. Labels en Evaluaci√≥n Final del Modelo
**Problema:**
```
ValueError: Number of given labels (100) not equal to the number of classes in 'y_score' (96)
```

**Causa:**
El modelo solo aprende las clases que ve durante entrenamiento (96), pero `encoders['target'].classes_` contiene todas las posibles (100). Las 4 clases faltantes son marcas con solo 1 ejemplo.

**Soluci√≥n:**
```python
# ‚ùå INCORRECTO
all_labels = np.arange(len(encoders['target'].classes_))
top3_acc = top_k_accuracy_score(y_test, y_pred_proba, k=3, labels=all_labels)

# ‚úÖ CORRECTO
model_labels = model.classes_  # Solo las clases que el modelo conoce
top3_acc = top_k_accuracy_score(y_test, y_pred_proba, k=3, labels=model_labels)
```

#### 3.3. Documentaci√≥n - Usar Todos los A√±os
**Archivo:** `backend/ml/README.md`

**Cambio:**
```bash
# ‚ùå ANTES (solo 2 a√±os)
python backend/ml/preparar_datos_propension.py --output data/ml/ --anios 2023,2024

# ‚úÖ AHORA (todos los a√±os disponibles)
python backend/ml/preparar_datos_propension.py --output data/ml/
```

**Beneficios:**
- Mayor precisi√≥n del modelo (m√°s datos)
- Captura de tendencias de largo plazo
- Mejor detecci√≥n de estacionalidad
- Reduce sobreajuste (overfitting)

---

## üìä Resultados Esperados

### Datasets Generados (Versi√≥n LITE)
- **Total registros:** 23,468
- **Marcas √∫nicas:** 100
- **A√±os de datos:** 7 (2019-2025)
- **Total inscripciones:** ~2.8M
- **Train set:** 18,774 muestras (80%)
- **Test set:** 4,694 muestras (20%)
- **Features:** 23

### Rendimiento Preliminar (Random Forest)
_Basado en corridas parciales antes del fix final:_
- **Cross-Validation (5 folds):**
  - Accuracy: 0.7069 ¬± 0.0056
  - F1 Weighted: 0.7010 ¬± 0.0058
  - Tiempo: ~13.56 segundos

- **Observaci√≥n:**
  - Train accuracy: 1.0000 (indica posible overfitting)
  - Podr√≠a beneficiarse de regularizaci√≥n adicional o poda

---

## üöÄ Pr√≥ximos Pasos

### Para Ejecutar el Pipeline Completo:

1. **Preparar Datos:**
```bash
python backend/ml/preparar_datos_propension_lite.py --output data/ml/
```

2. **Entrenar con Cross-Validation:**
```bash
# Versi√≥n b√°sica (sin grid search)
python backend/ml/entrenar_modelo_propension_cv.py --input data/ml/

# Con optimizaci√≥n de hiperpar√°metros (m√°s lento)
python backend/ml/entrenar_modelo_propension_cv.py --input data/ml/ --grid-search

# Solo Random Forest (m√°s r√°pido)
python backend/ml/entrenar_modelo_propension_cv.py --input data/ml/ --only-rf
```

3. **Revisar Resultados:**
- Modelos guardados en: `data/models/propension_compra_cv/`
- Archivos generados:
  - `{model_name}_modelo.joblib` - Modelo entrenado
  - `{model_name}_encoders.pkl` - Encoders de features
  - `{model_name}_metadata.json` - M√©tricas y configuraci√≥n
  - `feature_importance.png` - Importancia de features (si disponible)

---

## üìù Requisitos del Sistema

### Dependencias Python:
```bash
pip install -r requirements_ml.txt
```

### Acceso a Base de Datos:
- PostgreSQL 13+ corriendo en localhost:5432
- Base de datos: `mercado_automotor`
- Vistas KPI LITE creadas y actualizadas:
  - kpi_segmentacion_demografica_lite
  - kpi_financiamiento_lite
  - kpi_antiguedad_vehiculos_lite
  - kpi_demanda_activa_lite

---

## üéì Metodolog√≠a Implementada

### ¬øPor qu√© Cross-Validation?
1. **Evaluaci√≥n m√°s robusta:** Cada dato participa en validaci√≥n una vez
2. **Reduce varianza:** Promedio de 5 evaluaciones independientes
3. **Detecta overfitting:** Compara train vs validation en cada fold
4. **Estabilidad:** Desviaci√≥n est√°ndar indica consistencia del modelo

### ¬øPor qu√© Stratified?
- Mantiene la proporci√≥n de cada clase (marca) en cada fold
- Cr√≠tico para datasets desbalanceados (algunas marcas tienen pocas inscripciones)
- Previene folds con clases no representadas

### ¬øPor qu√© Top-K Accuracy?
En recomendaciones comerciales, no solo importa la predicci√≥n exacta:
- **Top-3:** ¬øLa marca correcta est√° en las 3 recomendaciones principales?
- **Top-5:** ¬øLa marca correcta est√° en las 5 recomendaciones principales?
- M√°s realista para casos de uso de marketing y recomendaci√≥n

---

## üîç Archivos Modificados

### Creados:
- `backend/ml/preparar_datos_propension_lite.py` - Versi√≥n r√°pida de preparaci√≥n
- `backend/ml/entrenar_modelo_propension_cv.py` - Entrenamiento con CV

### Modificados:
- `backend/ml/README.md` - Documentaci√≥n actualizada con mejores pr√°cticas
- `backend/ml/preparar_datos_propension.py` - Docstrings actualizados
- `backend/ml/entrenar_modelo_propension.py` - Fix de labels en top_k_accuracy_score
- `Iniciar_Dashboard_Mercado_Automotor.bat` - Correcci√≥n de puerto Ngrok

### Scripts de Utilidad:
- `backend/scripts/analizar_a√±os_disponibles.py` - Analizar a√±os en DB (creado, no ejecutado)

---

## üí° Lecciones Aprendidas

1. **Performance vs Completeness:**
   - A veces es mejor iterar r√°pido con features esenciales (LITE)
   - Luego expandir a features completas cuando el modelo base funciona

2. **Class Imbalance:**
   - Algunas marcas tienen muy pocos ejemplos (<2)
   - Estratificaci√≥n puede fallar ‚Üí necesario fallback sin stratify
   - El modelo no aprender√° clases que no ve en train

3. **Sklearn Labels Parameter:**
   - En CV: NO pasar labels (cada fold es diferente)
   - En evaluaci√≥n final: usar `model.classes_` no `encoder.classes_`

4. **Validaci√≥n del Usuario es Valiosa:**
   - Usuario sugiri√≥ CV y comparaci√≥n de modelos ‚Üí gran mejora metodol√≥gica
   - Usuario cuestion√≥ usar solo 2 a√±os ‚Üí ahora usamos todos

---

## üìß Contacto y Soporte

Para preguntas sobre esta implementaci√≥n:
- Ver documentaci√≥n: `backend/ml/README.md`
- Revisar logs de entrenamiento en: `data/models/propension_compra_cv/*.json`
- C√≥digo fuente comentado en detalle

---

_Documento generado: 2025-11-17_
_√öltima actualizaci√≥n: Commit 1179ddb_
