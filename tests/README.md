# Tests - Mercado Automotor

Suite completa de tests para el Sistema de Inteligencia Comercial del Mercado Automotor.

## ğŸ“Š Cobertura de Tests

La suite de tests cubre los siguientes componentes:

### âœ… Tests Unitarios (RÃ¡pidos)
- **test_validators.py**: Validadores Pydantic para datos scrapeados (80+ tests)
- **test_indicadores.py**: CÃ¡lculo de indicadores estratÃ©gicos (40+ tests)
- **test_models.py**: Modelos de base de datos y queries (30+ tests)
- **test_api_clients.py**: API clients con mocking (20+ tests)

### ğŸ”„ Tests de IntegraciÃ³n (Lentos)
- **test_scrapers_real.py**: Scrapers con datos reales de sitios web

**Total**: ~200+ tests

## ğŸš€ EjecuciÃ³n RÃ¡pida

```bash
# Todos los tests
./run_tests.sh

# Solo tests unitarios (rÃ¡pidos)
./run_tests.sh unit

# Con reporte de cobertura
./run_tests.sh coverage

# Tests especÃ­ficos
./run_tests.sh validators
./run_tests.sh indicadores
./run_tests.sh models
```

## ğŸ“– GuÃ­a de Tests

### 1. Tests de Validadores

**Archivo**: `test_validators.py`

**Cobertura**:
- ValidaciÃ³n de datos de patentamientos (ACARA/FACCARA)
- ValidaciÃ³n de datos de producciÃ³n (ADEFA)
- ValidaciÃ³n de indicadores BCRA
- ValidaciÃ³n de listados de MercadoLibre
- FunciÃ³n `validate_data()` con datasets mixtos

**Ejemplo**:
```bash
pytest tests/test_validators.py -v
```

**Tests Clave**:
- âœ… Datos vÃ¡lidos pasan validaciÃ³n
- âœ… Datos invÃ¡lidos son rechazados con mensajes claros
- âœ… NormalizaciÃ³n de campos (marcas, terminales)
- âœ… ValidaciÃ³n de rangos (precios, fechas, tasas)

### 2. Tests de Indicadores

**Archivo**: `test_indicadores.py`

**Cobertura**:
- Ãndice de TensiÃ³n de Demanda
- RotaciÃ³n de Stock por Terminal
- Ãndice de Accesibilidad de Compra
- Ranking de AtenciÃ³n de Marca
- FunciÃ³n `guardar_indicadores()`

**Ejemplo**:
```bash
pytest tests/test_indicadores.py -v
```

**Tests Clave**:
- âœ… CÃ¡lculo con datos completos
- âœ… Manejo de datos faltantes
- âœ… Estructura correcta de indicadores
- âœ… Guardado en base de datos
- âœ… ActualizaciÃ³n de duplicados

### 3. Tests de Modelos

**Archivo**: `test_models.py`

**Cobertura**:
- Modelo Patentamiento
- Modelo Produccion
- Modelo BCRAIndicador
- Modelo MercadoLibreListing
- Modelo IndicadorCalculado
- Relaciones entre modelos

**Ejemplo**:
```bash
pytest tests/test_models.py -v
```

**Tests Clave**:
- âœ… CreaciÃ³n de registros
- âœ… Queries y filtros
- âœ… Timestamps automÃ¡ticos
- âœ… Constraints Ãºnicos
- âœ… Campos JSON

### 4. Tests de API Clients

**Archivo**: `test_api_clients.py`

**Cobertura**:
- BCRAClient (con mocking)
- MercadoLibreClient (con mocking)
- Rate limiting
- Manejo de errores
- PaginaciÃ³n

**Ejemplo**:
```bash
pytest tests/test_api_clients.py -v
```

**Tests Clave**:
- âœ… Requests exitosos
- âœ… Manejo de errores HTTP
- âœ… Respeto de rate limits
- âœ… Parsing de respuestas JSON
- âœ… PaginaciÃ³n automÃ¡tica

### 5. Tests de Scrapers (IntegraciÃ³n)

**Archivo**: `test_scrapers_real.py`

âš ï¸ **IMPORTANTE**: Estos tests hacen requests REALES a sitios web. Ãšsalos con moderaciÃ³n.

**Cobertura**:
- ConexiÃ³n a ACARA/FACCARA
- ConexiÃ³n a ADEFA
- AnÃ¡lisis de estructura HTML
- Parsing de perÃ­odos
- ExtracciÃ³n de reportes

**Ejemplo**:
```bash
# Solo tests de integraciÃ³n
./run_tests.sh integration

# O especÃ­ficamente scrapers
pytest tests/test_scrapers_real.py -v -m integration
```

## ğŸ¯ Markers de Pytest

Los tests usan markers para categorizaciÃ³n:

```python
@pytest.mark.unit          # Tests unitarios rÃ¡pidos
@pytest.mark.slow          # Tests lentos (scrapers)
@pytest.mark.integration   # Tests de integraciÃ³n (requieren servicios externos)
@pytest.mark.requires_db   # Tests que requieren base de datos
```

**Uso**:
```bash
# Solo tests unitarios
pytest -m "not slow" -v

# Solo tests de integraciÃ³n
pytest -m integration -v

# Excluir tests lentos
pytest -m "not slow and not integration" -v
```

## ğŸ“ˆ Reporte de Cobertura

Generar reporte completo:

```bash
./run_tests.sh coverage
```

Esto genera:
- Reporte en terminal con lÃ­neas no cubiertas
- Reporte HTML en `htmlcov/index.html`

**Objetivo**: > 60% de cobertura

Ver reporte HTML:
```bash
# Linux/Mac
open htmlcov/index.html

# Windows
start htmlcov/index.html
```

## ğŸ› ï¸ Fixtures Compartidos

**Archivo**: `conftest.py`

Fixtures disponibles para todos los tests:

```python
# Database
db_session              # SesiÃ³n de BD en memoria
test_engine             # Engine de BD para tests

# Fechas
sample_fecha            # Fecha de ejemplo: 2024-01-15
sample_fecha_rango      # Rango de fechas (30 dÃ­as)

# Datos de ejemplo
sample_patentamiento_data
sample_produccion_data
sample_bcra_data
sample_meli_data
```

## ğŸ”§ ConfiguraciÃ³n

**Archivo**: `pytest.ini`

```ini
[pytest]
markers =
    slow: Tests lentos
    integration: Tests de integraciÃ³n
    unit: Tests unitarios
    requires_db: Requiere base de datos

# ConfiguraciÃ³n de logging
log_cli = true
log_cli_level = INFO
```

## ğŸ“ Escribir Nuevos Tests

### Template para test unitario:

```python
import pytest

def test_mi_funcion():
    """Test descripciÃ³n breve."""
    # Arrange
    input_data = {...}

    # Act
    result = mi_funcion(input_data)

    # Assert
    assert result is not None
    assert result['campo'] == valor_esperado
```

### Template para test con fixtures:

```python
def test_con_database(db_session, sample_data):
    """Test que usa BD."""
    # Usar db_session
    obj = MiModelo(**sample_data)
    db_session.add(obj)
    db_session.commit()

    # Verificar
    result = db_session.query(MiModelo).first()
    assert result is not None
```

### Template para test de integraciÃ³n:

```python
@pytest.mark.slow
@pytest.mark.integration
def test_api_real():
    """Test con API real."""
    client = MiAPIClient()
    result = client.fetch_data()

    assert result is not None
    assert len(result) > 0
```

## ğŸ› Debugging Tests

### Ejecutar un test especÃ­fico:
```bash
pytest tests/test_validators.py::TestPatentamientoValidator::test_patentamiento_valid -v
```

### Con output completo:
```bash
pytest tests/test_validators.py -v -s
```

### Con debugger:
```bash
pytest tests/test_validators.py --pdb
```

### Stop en primera falla:
```bash
pytest tests/ -x
```

## ğŸš¨ CI/CD Integration

Los tests pueden integrarse en GitHub Actions:

```yaml
# .github/workflows/test.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest tests/ -v --cov=backend
```

## ğŸ“š Recursos

- [Pytest Documentation](https://docs.pytest.org/)
- [Pytest-cov](https://pytest-cov.readthedocs.io/)
- [Python Testing Best Practices](https://realpython.com/python-testing/)

## ğŸ¤ Contribuir

Al agregar cÃ³digo nuevo:
1. âœ… Escribir tests para nuevas funcionalidades
2. âœ… Mantener cobertura > 60%
3. âœ… Ejecutar `./run_tests.sh coverage` antes de commit
4. âœ… Todos los tests deben pasar antes de merge

## ğŸ“ Soporte

Para problemas con tests:
1. Revisar logs: `pytest tests/ -v -s`
2. Verificar fixtures en `conftest.py`
3. Consultar documentaciÃ³n de Pytest
