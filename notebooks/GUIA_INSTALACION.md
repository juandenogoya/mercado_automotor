# ğŸš€ GuÃ­a de InstalaciÃ³n y EjecuciÃ³n - Pipeline ML

GuÃ­a paso a paso para ejecutar el pipeline de Machine Learning del proyecto Mercado Automotor.

---

## ğŸ“ InformaciÃ³n de la Rama

**Rama actual**: `claude/review-project-summary-011CV66WdV3iGNxtg8RMd2ZN`

Todos los scripts de ML estÃ¡n en esta rama.

---

## âœ… Pre-requisitos

Antes de comenzar, verifica que tengas:

1. âœ… **Python 3.8+** instalado
   ```powershell
   python --version
   # Debe mostrar: Python 3.8.x o superior
   ```

2. âœ… **PostgreSQL** con los datos cargados
   - Tablas: `datos_gob_inscripciones`, `datos_gob_transferencias`, `datos_gob_prendas`
   - Tablas: `ipc`, `badlar`, `tipo_cambio`, `indicadores_calculados`

3. âœ… **Archivo `.env`** con credenciales de base de datos
   ```
   DATABASE_URL=postgresql://usuario:password@host:puerto/mercado_automotor
   ```

---

## ğŸ“¦ PASO 1: Obtener el CÃ³digo

### En tu PC (Windows PowerShell):

```powershell
# Navegar al directorio del proyecto
cd C:\Users\juand\OneDrive\Escritorio\concecionaria\mercado_automotor

# Obtener los Ãºltimos cambios
git pull origin claude/review-project-summary-011CV66WdV3iGNxtg8RMd2ZN

# Verificar que estÃ¡s en la rama correcta
git branch --show-current
# Debe mostrar: claude/review-project-summary-011CV66WdV3iGNxtg8RMd2ZN

# Verificar que los archivos estÃ¡n presentes
dir notebooks\
# Debes ver: 01_preparacion_datos_ml.py, 02_modelado_predictivo.py, 03_predicciones.py
```

---

## ğŸ PASO 2: Crear Entorno Virtual (RECOMENDADO)

**Â¿Por quÃ© usar entorno virtual?**
- Aisla las dependencias del proyecto
- Evita conflictos con otros proyectos Python
- Facilita la gestiÃ³n de versiones

### OpciÃ³n A: Crear nuevo entorno virtual

```powershell
# Crear entorno virtual llamado 'venv_ml'
python -m venv venv_ml

# Activar el entorno virtual
.\venv_ml\Scripts\activate

# Debes ver (venv_ml) al inicio del prompt:
# (venv_ml) PS C:\Users\juand\OneDrive\Escritorio\concecionaria\mercado_automotor>
```

### OpciÃ³n B: Usar entorno virtual existente

Si ya tienes un entorno virtual del proyecto:

```powershell
# Activar entorno existente
.\venv\Scripts\activate
```

---

## ğŸ“š PASO 3: Instalar Dependencias

Con el entorno virtual activado:

```powershell
# Instalar dependencias de ML
pip install -r requirements_ml.txt

# Esto instalarÃ¡:
# - pandas, numpy
# - scikit-learn
# - xgboost, lightgbm
# - sqlalchemy, psycopg2-binary
# - pyarrow (para Parquet)
```

**Verificar instalaciÃ³n:**

```powershell
# Verificar que las librerÃ­as se instalaron correctamente
python -c "import pandas, sklearn, xgboost, lightgbm; print('âœ“ Todas las librerÃ­as instaladas')"
```

---

## ğŸ—‚ï¸ PASO 4: Verificar Estructura de Directorios

El pipeline crearÃ¡ automÃ¡ticamente las carpetas necesarias, pero puedes verificar:

```powershell
# Crear directorios si no existen (opcional)
mkdir -Force data\processed\ml
mkdir -Force data\models
mkdir -Force data\results
```

---

## â–¶ï¸ PASO 5: Ejecutar el Pipeline

### 5.1 PreparaciÃ³n de Datos (15-30 min)

Este script carga datos de PostgreSQL, los procesa y genera el dataset de ML.

```powershell
# Ejecutar script de preparaciÃ³n
python notebooks\01_preparacion_datos_ml.py
```

**QuÃ© hace:**
- âœ… Conecta a PostgreSQL
- âœ… Carga inscripciones, transferencias, prendas
- âœ… Carga variables macro (IPC, BADLAR, TC)
- âœ… Feature engineering (lag features, rolling averages)
- âœ… Guarda archivos Parquet en `data/processed/ml/`

**Outputs esperados:**
```
data/processed/ml/
â”œâ”€â”€ dataset_ml_completo.parquet    # Dataset completo
â”œâ”€â”€ dataset_ml_sample.parquet      # Top 20 marcas (para pruebas rÃ¡pidas)
â””â”€â”€ dataset_ml_metadata.csv        # Metadatos
```

**Logs clave a buscar:**
```
âœ“ Dataset unificado: XXX,XXX registros
âœ“ Variables macro unificadas: XX meses, XX variables
âœ“ Features creados: XX columnas totales
âœ… PREPARACIÃ“N COMPLETADA
```

---

### 5.2 Entrenamiento de Modelos (20-45 min)

Este script entrena 7 modelos de ML con optimizaciÃ³n de hiperparÃ¡metros.

```powershell
# Ejecutar entrenamiento
python notebooks\02_modelado_predictivo.py
```

**QuÃ© hace:**
- âœ… Carga dataset preparado
- âœ… Aplica Label Encoding y One-Hot Encoding
- âœ… Entrena 7 modelos con GridSearchCV
- âœ… EvalÃºa con MAE, RMSE, RÂ², MAPE
- âœ… Guarda mejor modelo y resultados

**Outputs esperados:**
```
data/models/
â”œâ”€â”€ mejor_modelo_LightGBM.pkl      # Mejor modelo (ejemplo)
â”œâ”€â”€ todos_modelos_<timestamp>.pkl  # Todos los modelos
â”œâ”€â”€ encoders.pkl                   # Encoders de variables categÃ³ricas
â””â”€â”€ feature_names.pkl              # Nombres de features

data/results/
â”œâ”€â”€ comparacion_modelos_<timestamp>.csv
â””â”€â”€ feature_importance_<modelo>.csv
```

**Logs clave a buscar:**
```
ğŸ† COMPARACIÃ“N DE MODELOS
Rank   Modelo          MAE Test    RÂ² Test
1      LightGBM        245.32      0.8542
2      XGBoost         258.19      0.8421
...

ğŸ¥‡ MEJOR MODELO: LightGBM
   RÂ² Test: 0.8542
âœ… MODELADO COMPLETADO
```

---

### 5.3 Predicciones (< 1 min)

Este script usa el modelo entrenado para hacer predicciones.

```powershell
# Ejecutar predicciones
python notebooks\03_predicciones.py
```

**QuÃ© hace:**
- âœ… Carga mejor modelo entrenado
- âœ… Hace predicciÃ³n de ejemplo (Toyota Corolla)
- âœ… Analiza mÃºltiples escenarios (optimista/base/pesimista)
- âœ… Guarda resultados

**Outputs esperados:**
```
data/results/
â””â”€â”€ predicciones_escenarios_<timestamp>.csv
```

---

## ğŸ” PASO 6: Revisar Resultados

### 6.1 ComparaciÃ³n de Modelos

```powershell
# Ver resultados de modelos
type data\results\comparacion_modelos_*.csv
```

### 6.2 Feature Importance

```powershell
# Ver quÃ© variables son mÃ¡s importantes
type data\results\feature_importance_*.csv
```

### 6.3 Predicciones de Escenarios

```powershell
# Ver predicciones bajo diferentes condiciones econÃ³micas
type data\results\predicciones_escenarios_*.csv
```

---

## âš™ï¸ CONFIGURACIÃ“N AVANZADA

### OpciÃ³n 1: Usar Dataset Completo (ProducciÃ³n)

Por defecto, el script usa `dataset_ml_sample.parquet` (top 20 marcas) para rapidez.

Para usar todos los datos:

```python
# Editar: notebooks/02_modelado_predictivo.py
# LÃ­nea ~60, cambiar:

# DE:
file_path = INPUT_DIR / "dataset_ml_sample.parquet"

# A:
file_path = INPUT_DIR / "dataset_ml_completo.parquet"
```

### OpciÃ³n 2: Desactivar GridSearchCV (Entrenamiento RÃ¡pido)

Para entrenar mÃ¡s rÃ¡pido sin optimizaciÃ³n:

```python
# Editar: notebooks/02_modelado_predictivo.py
# LÃ­nea ~430, cambiar:

# DE:
resultados, modelos_entrenados = entrenar_y_evaluar(
    X_train, X_test, y_train, y_test, modelos, usar_grid_search=True
)

# A:
resultados, modelos_entrenados = entrenar_y_evaluar(
    X_train, X_test, y_train, y_test, modelos, usar_grid_search=False
)
```

### OpciÃ³n 3: Entrenar Solo Algunos Modelos

Para entrenar solo modelos especÃ­ficos:

```python
# Editar: notebooks/02_modelado_predictivo.py
# En la funciÃ³n crear_modelos(), comentar los que no quieras:

modelos = {
    'Regresion_Lineal': {...},  # Mantener
    # 'Ridge': {...},           # Comentar
    # 'Lasso': {...},           # Comentar
    'Random_Forest': {...},     # Mantener
    'XGBoost': {...},           # Mantener
    # 'LightGBM': {...},        # Comentar
    # 'KNN': {...}              # Comentar
}
```

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "No module named 'xgboost'"

```powershell
pip install xgboost lightgbm
```

### Error: "Can't connect to PostgreSQL"

Verifica tu archivo `.env`:
```powershell
type .env
# Debe tener: DATABASE_URL=postgresql://...
```

### Error: "No se encuentra dataset_ml_sample.parquet"

Ejecuta primero el script de preparaciÃ³n:
```powershell
python notebooks\01_preparacion_datos_ml.py
```

### Advertencia: "SettingWithCopyWarning"

Es normal, son advertencias de pandas. Los scripts funcionan correctamente.

### Error de memoria (MemoryError)

Si el dataset es muy grande:
1. Usa `dataset_ml_sample.parquet` en lugar del completo
2. Reduce el perÃ­odo de anÃ¡lisis (editar filtro `>= '2020-01-01'`)
3. Aumenta RAM disponible o cierra otros programas

---

## ğŸ“Š Tiempos Estimados

| Script | DuraciÃ³n Estimada | Observaciones |
|--------|-------------------|---------------|
| 01_preparacion | 10-20 min | Depende de cantidad de datos en PostgreSQL |
| 02_modelado (con GridSearch) | 30-45 min | 7 modelos Ã— mÃºltiples hiperparÃ¡metros |
| 02_modelado (sin GridSearch) | 5-10 min | MÃ¡s rÃ¡pido, parÃ¡metros por defecto |
| 03_predicciones | < 1 min | Muy rÃ¡pido |

---

## ğŸ”„ Flujo Completo Resumido

```powershell
# 1. Preparar entorno
git pull
python -m venv venv_ml
.\venv_ml\Scripts\activate
pip install -r requirements_ml.txt

# 2. Ejecutar pipeline
python notebooks\01_preparacion_datos_ml.py    # ~15 min
python notebooks\02_modelado_predictivo.py     # ~30 min
python notebooks\03_predicciones.py            # < 1 min

# 3. Revisar resultados
dir data\results\
type data\results\comparacion_modelos_*.csv
```

---

## ğŸ“ Checklist Pre-EjecuciÃ³n

Antes de ejecutar, verifica:

- [ ] Estoy en la rama correcta (`claude/review-project-summary-011CV66WdV3iGNxtg8RMd2ZN`)
- [ ] Tengo Python 3.8+ instalado
- [ ] PostgreSQL tiene los datos cargados
- [ ] Archivo `.env` existe con DATABASE_URL correcta
- [ ] Entorno virtual estÃ¡ activado
- [ ] Dependencias instaladas (`pip install -r requirements_ml.txt`)
- [ ] Tengo ~2GB de espacio en disco para outputs

---

## ğŸ“ Archivos que se GenerarÃ¡n

DespuÃ©s de ejecutar todo, tendrÃ¡s:

```
mercado_automotor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/ml/
â”‚   â”‚   â”œâ”€â”€ dataset_ml_completo.parquet      (~100-500 MB)
â”‚   â”‚   â”œâ”€â”€ dataset_ml_sample.parquet        (~20-50 MB)
â”‚   â”‚   â””â”€â”€ dataset_ml_metadata.csv          (< 1 MB)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ mejor_modelo_LightGBM.pkl        (~10-50 MB)
â”‚   â”‚   â”œâ”€â”€ todos_modelos_<timestamp>.pkl    (~50-200 MB)
â”‚   â”‚   â”œâ”€â”€ encoders.pkl                     (< 1 MB)
â”‚   â”‚   â””â”€â”€ feature_names.pkl                (< 1 MB)
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ comparacion_modelos_*.csv        (< 1 MB)
â”‚       â”œâ”€â”€ feature_importance_*.csv         (< 1 MB)
â”‚       â””â”€â”€ predicciones_escenarios_*.csv    (< 1 MB)
â””â”€â”€ notebooks/
    â””â”€â”€ ... (scripts de Python)
```

**Espacio total requerido**: ~500 MB - 1 GB

---

## ğŸ¯ PrÃ³ximos Pasos DespuÃ©s de Ejecutar

1. **Revisar modelo ganador**:
   - Abrir `comparacion_modelos_*.csv`
   - Identificar modelo con mejor RÂ² Test

2. **Analizar feature importance**:
   - Abrir `feature_importance_*.csv`
   - Identificar variables mÃ¡s predictivas

3. **Interpretar predicciones**:
   - Abrir `predicciones_escenarios_*.csv`
   - Comparar escenarios optimista vs pesimista

4. **Opcional - Integrar al dashboard**:
   - Agregar predicciones al Streamlit
   - Crear visualizaciones interactivas

---

**Â¿Listo para empezar?** ğŸš€

Empieza con: `python notebooks\01_preparacion_datos_ml.py`
