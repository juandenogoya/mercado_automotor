# ü§ñ Pipeline de Machine Learning - Mercado Automotor

Pipeline completo de an√°lisis predictivo para predecir la demanda de veh√≠culos en Argentina integrando variables macro-econ√≥micas.

---

## üìã √çndice

1. [Objetivo](#objetivo)
2. [Datasets Utilizados](#datasets-utilizados)
3. [Pipeline de Trabajo](#pipeline-de-trabajo)
4. [Modelos Implementados](#modelos-implementados)
5. [Ejecuci√≥n](#ejecuci√≥n)
6. [Resultados Esperados](#resultados-esperados)
7. [Uso de Predicciones](#uso-de-predicciones)

---

## üéØ Objetivo

**Predecir la demanda mensual de veh√≠culos** (cantidad de transacciones) por marca, modelo y provincia, considerando variables macro-econ√≥micas para evaluar c√≥mo factores econ√≥micos afectan el mercado automotriz.

### Variable Target
- **`cantidad_transacciones`**: Volumen mensual de transacciones por marca/modelo/provincia/tipo

### Casos de Uso
1. **Planificaci√≥n de inventario**: Proyectar demanda futura por marca/modelo
2. **An√°lisis de sensibilidad**: Evaluar impacto de variables macro (IPC, BADLAR, TC)
3. **Estrategia comercial**: Identificar oportunidades por provincia/segmento
4. **Evaluaci√≥n de escenarios**: Simular demanda bajo diferentes condiciones econ√≥micas

---

## üìä Datasets Utilizados

### Datasets Transaccionales (DNRPA - datos.gob.ar)
- **`datos_gob_inscripciones`**: Inscripciones iniciales 0km (~3M registros)
- **`datos_gob_transferencias`**: Transferencias veh√≠culos usados (~9M registros)
- **`datos_gob_prendas`**: Prendas veh√≠culos financiados (~2M registros)

**Variables clave**:
- `tramite_fecha`: Fecha de la transacci√≥n
- `automotor_marca_descripcion`: Marca del veh√≠culo
- `automotor_modelo_descripcion`: Modelo del veh√≠culo
- `registro_seccional_provincia`: Provincia
- `titular_genero`: G√©nero del titular
- `titular_anio_nacimiento`: A√±o de nacimiento (para calcular edad)
- `automotor_anio_modelo`: A√±o del modelo

### Datasets Macro-econ√≥micos
- **`ipc`**: √çndice de Precios al Consumidor (INDEC)
  - `nivel_general`, `variacion_mensual`, `variacion_interanual`

- **`badlar`**: Tasa BADLAR (BCRA)
  - Promedio mensual y volatilidad

- **`tipo_cambio`**: Tipo de cambio oficial (BCRA)
  - Promedio mensual y volatilidad

- **`indicadores_calculados`**: Indicadores derivados
  - `tasa_real`: Tasa de inter√©s real (BADLAR - IPC)
  - `tcr`: Tipo de cambio real
  - `accesibilidad`: √çndice de accesibilidad automotriz
  - `volatilidad`: Volatilidad macro agregada

---

## üîÑ Pipeline de Trabajo

### Script 1: `01_preparacion_datos_ml.py`

**Prop√≥sito**: Carga, unifica y prepara datos para ML

**Pasos**:
1. **Carga de datos transaccionales**
   - Unifica inscripciones, transferencias y prendas
   - A√±ade columna `tipo_transaccion` para identificar origen
   - Filtra desde 2020 en adelante

2. **Carga de variables macro**
   - Obtiene IPC, BADLAR, Tipo de Cambio, Indicadores calculados
   - Agrega a nivel mensual
   - Forward-fill para valores faltantes

3. **Agregaci√≥n de transacciones**
   - Agrupa por: `fecha_mes`, `marca`, `modelo`, `provincia`, `tipo_transaccion`, `genero`
   - Calcula: cantidad de transacciones, edad promedio, a√±o modelo promedio

4. **Feature Engineering**
   - Variables temporales: `trimestre`, `es_primer_semestre`, `es_fin_anio`
   - Lag features: valores del mes anterior (lag1) y hace 3 meses (lag3)
   - Rolling averages: MA3, MA6 (promedios m√≥viles)
   - Variaci√≥n intermensual de cantidad
   - Rangos de edad: '18-25', '26-35', '36-45', '46-55', '56-65', '65+'

5. **Guardado**
   - `dataset_ml_completo.parquet`: Dataset completo
   - `dataset_ml_sample.parquet`: Top 20 marcas (para desarrollo r√°pido)
   - `dataset_ml_metadata.csv`: Metadatos de columnas

**Ejecuci√≥n**:
```bash
python notebooks/01_preparacion_datos_ml.py
```

**Outputs**:
- `data/processed/ml/dataset_ml_completo.parquet`
- `data/processed/ml/dataset_ml_sample.parquet`
- `data/processed/ml/dataset_ml_metadata.csv`

---

### Script 2: `02_modelado_predictivo.py`

**Prop√≥sito**: Entrenar y evaluar m√∫ltiples modelos de ML

**Pasos**:
1. **Carga de datos preparados**
   - Lee dataset de muestra o completo

2. **Identificaci√≥n de tipos de columnas**
   - Num√©ricas: variables continuas
   - Categ√≥ricas alta cardinalidad: `marca`, `modelo` ‚Üí **Label Encoding**
   - Categ√≥ricas baja cardinalidad: `provincia`, `genero`, `tipo_transaccion` ‚Üí **One-Hot Encoding**

3. **Preparaci√≥n de features**
   - Aplica Label Encoding para alta cardinalidad
   - Aplica One-Hot Encoding para baja cardinalidad
   - Imputa NaN con mediana (variables num√©ricas)
   - Genera vector de features final

4. **Split Train/Test**
   - 80% entrenamiento, 20% prueba
   - Random state 42 para reproducibilidad

5. **Entrenamiento de modelos** (con GridSearchCV)
   - Regresi√≥n Lineal (baseline)
   - Ridge Regression
   - Lasso Regression
   - Random Forest
   - XGBoost
   - LightGBM
   - KNN

6. **Evaluaci√≥n**
   - M√©tricas: MAE, RMSE, R¬≤, MAPE
   - Comparaci√≥n Train vs Test (detectar overfitting)
   - Ranking de modelos por R¬≤ Test

7. **Guardado**
   - Mejor modelo
   - Todos los modelos
   - Encoders
   - Feature names
   - Feature importance
   - Comparaci√≥n de resultados

**Ejecuci√≥n**:
```bash
python notebooks/02_modelado_predictivo.py
```

**Outputs**:
- `data/models/mejor_modelo_<nombre>.pkl`
- `data/models/todos_modelos_<timestamp>.pkl`
- `data/models/encoders.pkl`
- `data/models/feature_names.pkl`
- `data/results/comparacion_modelos_<timestamp>.csv`
- `data/results/feature_importance_<nombre>.csv`

---

### Script 3: `03_predicciones.py`

**Prop√≥sito**: Realizar predicciones con modelos entrenados

**Funcionalidades**:
1. **Predicci√≥n simple**: Para una combinaci√≥n marca/modelo/provincia/mes
2. **Predicci√≥n m√∫ltiples escenarios**: Simula escenarios optimista/base/pesimista

**Escenarios definidos**:
- **Optimista**: IPC bajo, BADLAR moderada, TC estable
- **Base**: Condiciones actuales
- **Pesimista**: IPC alto, BADLAR alta, TC en alza

**Ejecuci√≥n**:
```bash
python notebooks/03_predicciones.py
```

**Outputs**:
- `data/results/predicciones_escenarios_<timestamp>.csv`

---

## ü§ñ Modelos Implementados

### 1. Regresi√≥n Lineal (Baseline)
- **Prop√≥sito**: Modelo simple para establecer benchmark
- **Ventajas**: Interpretable, r√°pido
- **Limitaciones**: Asume relaciones lineales

### 2. Ridge & Lasso Regression
- **Prop√≥sito**: Regularizaci√≥n para evitar overfitting
- **Ridge**: Penaliza L2 (magnitud de coeficientes)
- **Lasso**: Penaliza L1 (feature selection)

### 3. Random Forest Regressor
- **Prop√≥sito**: Ensemble de √°rboles de decisi√≥n
- **Ventajas**: No lineal, maneja interacciones, robusto
- **Hiperpar√°metros**: n_estimators, max_depth, min_samples_split

### 4. XGBoost
- **Prop√≥sito**: Gradient Boosting optimizado
- **Ventajas**: Alta performance, maneja missing values
- **Hiperpar√°metros**: learning_rate, max_depth, subsample

### 5. LightGBM
- **Prop√≥sito**: Gradient Boosting r√°pido y eficiente
- **Ventajas**: R√°pido en datasets grandes, maneja categ√≥ricas
- **Hiperpar√°metros**: num_leaves, learning_rate, max_depth

### 6. KNN Regressor
- **Prop√≥sito**: Vecinos m√°s cercanos
- **Ventajas**: No param√©trico, simple
- **Hiperpar√°metros**: n_neighbors, weights, metric

---

## üöÄ Ejecuci√≥n

### Paso 1: Preparaci√≥n de datos
```bash
cd /path/to/mercado_automotor
python notebooks/01_preparacion_datos_ml.py
```

**Duraci√≥n estimada**: 5-15 minutos (seg√∫n tama√±o de datos)

### Paso 2: Entrenamiento de modelos
```bash
python notebooks/02_modelado_predictivo.py
```

**Duraci√≥n estimada**: 15-30 minutos (con GridSearchCV)

**Para entrenamiento r√°pido** (sin GridSearch):
- Editar script y cambiar `usar_grid_search=False`

### Paso 3: Predicciones
```bash
python notebooks/03_predicciones.py
```

**Duraci√≥n estimada**: < 1 minuto

---

## üìà Resultados Esperados

### M√©tricas de Evaluaci√≥n

| M√©trica | Descripci√≥n | Interpretaci√≥n |
|---------|-------------|----------------|
| **MAE** | Mean Absolute Error | Error promedio en cantidad de transacciones |
| **RMSE** | Root Mean Squared Error | Error penalizando grandes desviaciones |
| **R¬≤** | Coeficiente de determinaci√≥n | % de varianza explicada (0-1, ideal cercano a 1) |
| **MAPE** | Mean Absolute Percentage Error | Error porcentual promedio |

### Ejemplo de Resultados

```
================================================================================
Rank   Modelo               MAE Test     RMSE Test    R¬≤ Test      MAPE Test
================================================================================
1      LightGBM             245.32       412.18       0.8542       12.34%
2      XGBoost              258.19       428.65       0.8421       13.12%
3      Random_Forest        267.84       445.23       0.8298       14.05%
4      Ridge                312.45       502.18       0.7845       16.78%
5      Regresion_Lineal     318.92       515.34       0.7723       17.34%
6      Lasso                325.67       528.91       0.7612       18.01%
7      KNN                  389.23       612.45       0.6834       21.45%
================================================================================
```

### Feature Importance (Top 10)

Variables m√°s importantes para predicci√≥n:
1. `cantidad_transacciones_lag1` - Valor mes anterior
2. `cantidad_ma3` - Promedio m√≥vil 3 meses
3. `ipc_var_mensual` - Variaci√≥n IPC
4. `badlar_promedio` - Tasa BADLAR
5. `marca_encoded` - Marca del veh√≠culo
6. `mes` - Estacionalidad
7. `tc_promedio` - Tipo de cambio
8. `provincia_encoded` - Provincia
9. `tasa_real_promedio` - Tasa de inter√©s real
10. `edad_titular` - Edad promedio compradores

---

## üîÆ Uso de Predicciones

### Ejemplo 1: Predicci√≥n para un mes espec√≠fico

```python
from notebooks.predicciones import cargar_modelo_y_artefactos, preparar_datos_prediccion, predecir

# Cargar modelo
modelo, encoders, feature_names = cargar_modelo_y_artefactos()

# Preparar datos
df_pred = preparar_datos_prediccion(
    marca="TOYOTA",
    modelo_nombre="COROLLA",
    provincia="CAPITAL FEDERAL",
    tipo_transaccion="inscripcion",
    mes_prediccion=12,
    anio_prediccion=2024
)

# Predecir
prediccion = predecir(modelo, encoders, feature_names, df_pred)
print(f"Predicci√≥n: {prediccion:.0f} transacciones")
```

### Ejemplo 2: An√°lisis de sensibilidad macro

```python
# Escenario optimista (IPC bajo, econom√≠a estable)
df_pred['ipc_var_mensual'] = 3.0
df_pred['badlar_promedio'] = 45.0
prediccion_opt = predecir(modelo, encoders, feature_names, df_pred)

# Escenario pesimista (IPC alto, econom√≠a vol√°til)
df_pred['ipc_var_mensual'] = 8.0
df_pred['badlar_promedio'] = 65.0
prediccion_pes = predecir(modelo, encoders, feature_names, df_pred)

print(f"Diferencia: {prediccion_pes - prediccion_opt:.0f} transacciones")
```

---

## üìÅ Estructura de Archivos Generados

```
mercado_automotor/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dataset_ml_completo.parquet     # Dataset completo
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dataset_ml_sample.parquet       # Dataset muestra
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dataset_ml_metadata.csv         # Metadatos
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mejor_modelo_LightGBM.pkl          # Mejor modelo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ todos_modelos_<timestamp>.pkl      # Todos los modelos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encoders.pkl                       # Encoders categ√≥ricos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_names.pkl                  # Nombres de features
‚îÇ   ‚îî‚îÄ‚îÄ results/
‚îÇ       ‚îú‚îÄ‚îÄ comparacion_modelos_<timestamp>.csv
‚îÇ       ‚îú‚îÄ‚îÄ feature_importance_<modelo>.csv
‚îÇ       ‚îî‚îÄ‚îÄ predicciones_escenarios_<timestamp>.csv
‚îî‚îÄ‚îÄ notebooks/
    ‚îú‚îÄ‚îÄ 01_preparacion_datos_ml.py
    ‚îú‚îÄ‚îÄ 02_modelado_predictivo.py
    ‚îú‚îÄ‚îÄ 03_predicciones.py
    ‚îî‚îÄ‚îÄ README_ML.md
```

---

## üîß Configuraci√≥n y Dependencias

### Librer√≠as Requeridas

```bash
pip install pandas numpy scikit-learn xgboost lightgbm
pip install sqlalchemy psycopg2-binary
pip install pyarrow  # para parquet
```

### Variables de Entorno

El script usa `backend.config.settings` que lee de `.env`:
```
DATABASE_URL=postgresql://user:password@host:port/mercado_automotor
```

---

## üí° Tips y Mejores Pr√°cticas

### Para Desarrollo R√°pido
- Usar `dataset_ml_sample.parquet` (top 20 marcas)
- Desactivar GridSearchCV: `usar_grid_search=False`
- Reducir hiperpar√°metros a probar en `crear_modelos()`

### Para Producci√≥n
- Usar `dataset_ml_completo.parquet`
- Activar GridSearchCV con m√°s iteraciones
- Considerar validaci√≥n cruzada temporal (TimeSeriesSplit)

### Optimizaciones Futuras
1. **Feature Engineering avanzado**:
   - Interacciones entre variables macro
   - Tendencias de largo plazo
   - Componentes estacionales ARIMA

2. **Modelos adicionales**:
   - Prophet (Facebook) para series temporales
   - LSTM/GRU (Deep Learning)
   - Ensemble stacking de mejores modelos

3. **Validaci√≥n robusta**:
   - Cross-validation temporal
   - Backtesting con ventanas deslizantes
   - An√°lisis de residuos

4. **Deployment**:
   - API REST para predicciones
   - Dashboard interactivo (Streamlit)
   - Re-entrenamiento autom√°tico mensual

---

## üìû Soporte

Para preguntas o problemas:
1. Revisar logs de ejecuci√≥n
2. Verificar que datos est√©n en PostgreSQL
3. Confirmar que `01_preparacion_datos_ml.py` complet√≥ exitosamente

---

**Autor**: Pipeline de ML - Mercado Automotor Argentino
**√öltima actualizaci√≥n**: 2024
